{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: use reinforcement learning to solve the breakout problem in Atari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym                                                      # import the openAI gym\n",
    "from stable_baselines3 import A2C                               # import algorithm\n",
    "from stable_baselines3.common.vec_env import VecFrameStack      # import stuff for vectorizing environment (speed up training)\n",
    "from stable_baselines3.common.evaluation import evaluate_policy # import policy evaluation stuff\n",
    "from stable_baselines3.common.env_util import make_atari_env    # for working with atari environment\n",
    "import os                                                       # for paths and stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the Atari ROMs use:\n",
    "# pip install gymnasium[accept-rom-license]\n",
    "#\n",
    "# See this link for more info:\n",
    "# https://gymnasium.farama.org/environments/atari/#atari\n",
    "\n",
    "environment_name = 'Breakout-v4'\n",
    "env = gym.make(environment_name,render_mode = 'human')\n",
    "env.close()   # comment this out to see the computer play atari\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {'lives': 5, 'episode_frame_number': 0, 'frame_number': 0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the type of action space\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is an image based model (dimensions of the image reported here)\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joe\\Documents\\MachineLearningProjects\\StableBaselinesTutorials\\.venv\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\Joe\\Documents\\MachineLearningProjects\\StableBaselinesTutorials\\.venv\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:2.0\n",
      "Episode:2 Score:0.0\n",
      "Episode:3 Score:0.0\n",
      "Episode:4 Score:2.0\n",
      "Episode:5 Score:0.0\n"
     ]
    }
   ],
   "source": [
    "# loop for testing environment\n",
    "episodes = 5\n",
    "for episode in range(1,episodes+1):\n",
    "    obs = env.reset()[0]\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        # make the render\n",
    "        env.render()\n",
    "\n",
    "        # NOW USING MODEL HERE!!\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # take a step using the action and return the new state, reward, is the episode done? x2, info\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = truncated or terminated\n",
    "\n",
    "        # aggregate the reward\n",
    "        score += reward\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Vectorize Environment and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env('Breakout-v4', n_envs=4, seed=0)   # helper function for making the environment\n",
    "env = VecFrameStack(env, n_stack=4)                     # wrapper for stacking environments together\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# set up the model for training\n",
    "log_path = os.path.join('Training', 'Logs')\n",
    "model = A2C('CnnPolicy', env, verbose=1, tensorboard_log=log_path)  # different algorithm from PPO or DQN, using CNN policy instead of MLP because our observations are an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 272      |\n",
      "|    ep_rew_mean        | 1.36     |\n",
      "| time/                 |          |\n",
      "|    fps                | 324      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.0783   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.0368   |\n",
      "|    value_loss         | 0.0553   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 285      |\n",
      "|    ep_rew_mean        | 1.63     |\n",
      "| time/                 |          |\n",
      "|    fps                | 405      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0.585    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.246   |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 296      |\n",
      "|    ep_rew_mean        | 1.88     |\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0.857    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.0189   |\n",
      "|    value_loss         | 0.0481   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | 2.15     |\n",
      "| time/                 |          |\n",
      "|    fps                | 324      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.642   |\n",
      "|    explained_variance | -0.287   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.0303   |\n",
      "|    value_loss         | 0.129    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 318      |\n",
      "|    ep_rew_mean        | 2.3      |\n",
      "| time/                 |          |\n",
      "|    fps                | 284      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.258   |\n",
      "|    explained_variance | 0.597    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.00555  |\n",
      "|    value_loss         | 0.058    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 317      |\n",
      "|    ep_rew_mean        | 2.22     |\n",
      "| time/                 |          |\n",
      "|    fps                | 260      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.632   |\n",
      "|    explained_variance | 0.944    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.0111  |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | 2.15     |\n",
      "| time/                 |          |\n",
      "|    fps                | 248      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.426   |\n",
      "|    explained_variance | 0.975    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.00824  |\n",
      "|    value_loss         | 0.0179   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | 2.13     |\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 0.974    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.0076   |\n",
      "|    value_loss         | 0.0167   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 319      |\n",
      "|    ep_rew_mean        | 2.29     |\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.919    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.0479  |\n",
      "|    value_loss         | 0.0467   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 318      |\n",
      "|    ep_rew_mean        | 2.32     |\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.0199  |\n",
      "|    value_loss         | 0.00814  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 325      |\n",
      "|    ep_rew_mean        | 2.42     |\n",
      "| time/                 |          |\n",
      "|    fps                | 222      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.277    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.298    |\n",
      "|    value_loss         | 0.293    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 320      |\n",
      "|    ep_rew_mean        | 2.37     |\n",
      "| time/                 |          |\n",
      "|    fps                | 217      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0.82     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.11    |\n",
      "|    value_loss         | 0.0385   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 317      |\n",
      "|    ep_rew_mean        | 2.31     |\n",
      "| time/                 |          |\n",
      "|    fps                | 214      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | 0.896    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.145    |\n",
      "|    value_loss         | 0.0453   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 321      |\n",
      "|    ep_rew_mean        | 2.42     |\n",
      "| time/                 |          |\n",
      "|    fps                | 212      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.863   |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.128    |\n",
      "|    value_loss         | 0.0318   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 324      |\n",
      "|    ep_rew_mean        | 2.48     |\n",
      "| time/                 |          |\n",
      "|    fps                | 211      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.99    |\n",
      "|    explained_variance | 0.981    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.0249  |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | 2.55     |\n",
      "| time/                 |          |\n",
      "|    fps                | 210      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.0344   |\n",
      "|    value_loss         | 0.0161   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | 2.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 209      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.125    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.119    |\n",
      "|    value_loss         | 0.209    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 339      |\n",
      "|    ep_rew_mean        | 2.77     |\n",
      "| time/                 |          |\n",
      "|    fps                | 208      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.783    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.0828   |\n",
      "|    value_loss         | 0.0331   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 361      |\n",
      "|    ep_rew_mean        | 3.2      |\n",
      "| time/                 |          |\n",
      "|    fps                | 208      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.68    |\n",
      "|    explained_variance | 0.63     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.189    |\n",
      "|    value_loss         | 0.235    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 375      |\n",
      "|    ep_rew_mean        | 3.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 208      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.475   |\n",
      "|    explained_variance | 0.978    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.0563  |\n",
      "|    value_loss         | 0.0132   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 394      |\n",
      "|    ep_rew_mean        | 3.99     |\n",
      "| time/                 |          |\n",
      "|    fps                | 208      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.334   |\n",
      "|    explained_variance | 0.887    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.18    |\n",
      "|    value_loss         | 0.0338   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 383      |\n",
      "|    ep_rew_mean        | 3.8      |\n",
      "| time/                 |          |\n",
      "|    fps                | 207      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.27    |\n",
      "|    explained_variance | 0.866    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.0287   |\n",
      "|    value_loss         | 0.0527   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 364      |\n",
      "|    ep_rew_mean        | 3.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 207      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.407   |\n",
      "|    explained_variance | 0.975    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.0505  |\n",
      "|    value_loss         | 0.0169   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 367      |\n",
      "|    ep_rew_mean        | 3.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 207      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.736   |\n",
      "|    explained_variance | 0.912    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.0502  |\n",
      "|    value_loss         | 0.0387   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 380      |\n",
      "|    ep_rew_mean        | 3.81     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.359   |\n",
      "|    explained_variance | 0.892    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.0156   |\n",
      "|    value_loss         | 0.0777   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 399      |\n",
      "|    ep_rew_mean        | 4.24     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.772   |\n",
      "|    explained_variance | 0.971    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.0369   |\n",
      "|    value_loss         | 0.0488   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 424      |\n",
      "|    ep_rew_mean        | 4.85     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.18    |\n",
      "|    explained_variance | 0.817    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.077   |\n",
      "|    value_loss         | 0.0622   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 446      |\n",
      "|    ep_rew_mean        | 5.36     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.138   |\n",
      "|    explained_variance | 0.978    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0347  |\n",
      "|    value_loss         | 0.042    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 455      |\n",
      "|    ep_rew_mean        | 5.46     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.242   |\n",
      "|    explained_variance | 0.973    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.00234 |\n",
      "|    value_loss         | 0.0338   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 448      |\n",
      "|    ep_rew_mean        | 5.35     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.373   |\n",
      "|    explained_variance | 0.858    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.0204  |\n",
      "|    value_loss         | 0.0559   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 444      |\n",
      "|    ep_rew_mean        | 5.29     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.275   |\n",
      "|    explained_variance | 0.944    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.0133  |\n",
      "|    value_loss         | 0.0262   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 440      |\n",
      "|    ep_rew_mean        | 5.1      |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.466   |\n",
      "|    explained_variance | 0.913    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.255   |\n",
      "|    value_loss         | 0.0806   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 438      |\n",
      "|    ep_rew_mean        | 4.97     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.506   |\n",
      "|    explained_variance | -6.75    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.211    |\n",
      "|    value_loss         | 0.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 435      |\n",
      "|    ep_rew_mean        | 4.86     |\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.329   |\n",
      "|    explained_variance | 0.686    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0382   |\n",
      "|    value_loss         | 0.151    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 441      |\n",
      "|    ep_rew_mean        | 5.03     |\n",
      "| time/                 |          |\n",
      "|    fps                | 205      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.232   |\n",
      "|    explained_variance | 0.911    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.00872 |\n",
      "|    value_loss         | 0.0829   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 452      |\n",
      "|    ep_rew_mean        | 5.2      |\n",
      "| time/                 |          |\n",
      "|    fps                | 205      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 350      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.585   |\n",
      "|    explained_variance | 0.904    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.0176   |\n",
      "|    value_loss         | 0.0951   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 456      |\n",
      "|    ep_rew_mean        | 5.21     |\n",
      "| time/                 |          |\n",
      "|    fps                | 205      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.148   |\n",
      "|    explained_variance | 0.798    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.0359   |\n",
      "|    value_loss         | 0.167    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 478      |\n",
      "|    ep_rew_mean        | 5.72     |\n",
      "| time/                 |          |\n",
      "|    fps                | 205      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 369      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.237   |\n",
      "|    explained_variance | 0.569    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.0394   |\n",
      "|    value_loss         | 0.226    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 493      |\n",
      "|    ep_rew_mean        | 5.97     |\n",
      "| time/                 |          |\n",
      "|    fps                | 205      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 380      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.342   |\n",
      "|    explained_variance | 0.912    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.0448  |\n",
      "|    value_loss         | 0.0741   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 498      |\n",
      "|    ep_rew_mean        | 6.05     |\n",
      "| time/                 |          |\n",
      "|    fps                | 204      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 390      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.455   |\n",
      "|    explained_variance | 0.946    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.102   |\n",
      "|    value_loss         | 0.0471   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 513      |\n",
      "|    ep_rew_mean        | 6.3      |\n",
      "| time/                 |          |\n",
      "|    fps                | 204      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 400      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.222   |\n",
      "|    explained_variance | 0.72     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.00587  |\n",
      "|    value_loss         | 0.178    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 512      |\n",
      "|    ep_rew_mean        | 6.28     |\n",
      "| time/                 |          |\n",
      "|    fps                | 204      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.26    |\n",
      "|    explained_variance | 0.871    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.0433   |\n",
      "|    value_loss         | 0.0814   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 466      |\n",
      "|    ep_rew_mean        | 5.41     |\n",
      "| time/                 |          |\n",
      "|    fps                | 204      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0101  |\n",
      "|    explained_variance | 0.878    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.00015 |\n",
      "|    value_loss         | 0.0256   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 411       |\n",
      "|    ep_rew_mean        | 4.44      |\n",
      "| time/                 |           |\n",
      "|    fps                | 204       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 430       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.304    |\n",
      "|    explained_variance | 0.956     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -0.000545 |\n",
      "|    value_loss         | 0.0512    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 417      |\n",
      "|    ep_rew_mean        | 4.48     |\n",
      "| time/                 |          |\n",
      "|    fps                | 204      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 440      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.105   |\n",
      "|    explained_variance | 0.544    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.00828  |\n",
      "|    value_loss         | 0.162    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 418      |\n",
      "|    ep_rew_mean        | 4.55     |\n",
      "| time/                 |          |\n",
      "|    fps                | 204      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 450      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.319   |\n",
      "|    explained_variance | 0.88     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.0182   |\n",
      "|    value_loss         | 0.0555   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 420      |\n",
      "|    ep_rew_mean        | 4.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 203      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 461      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.458   |\n",
      "|    explained_variance | 0.492    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.0542  |\n",
      "|    value_loss         | 0.126    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 462      |\n",
      "|    ep_rew_mean        | 5.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 203      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 471      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.18    |\n",
      "|    explained_variance | 0.455    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.00392  |\n",
      "|    value_loss         | 0.0638   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 512      |\n",
      "|    ep_rew_mean        | 6.38     |\n",
      "| time/                 |          |\n",
      "|    fps                | 203      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 481      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.18    |\n",
      "|    explained_variance | 0.928    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.00687 |\n",
      "|    value_loss         | 0.0444   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 531      |\n",
      "|    ep_rew_mean        | 6.86     |\n",
      "| time/                 |          |\n",
      "|    fps                | 203      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 491      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.188   |\n",
      "|    explained_variance | 0.114    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.104    |\n",
      "|    value_loss         | 0.317    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x2865ae26a50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train for 100,000 time steps\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_path = os.path.join('Training','Saved Models','A2C_Breakout_Model')\n",
    "model.save(a2c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joe\\Documents\\MachineLearningProjects\\StableBaselinesTutorials\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Observation spaces do not match: Box(0, 255, (4, 84, 84), uint8) != Box(0, 255, (3, 210, 160), uint8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m a2c_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaved Models\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA2C_Breakout_Model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mA2C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma2c_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joe\\Documents\\MachineLearningProjects\\StableBaselinesTutorials\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:717\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_env(env, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# Check if given env is valid\u001b[39;00m\n\u001b[1;32m--> 717\u001b[0m \u001b[43mcheck_for_correct_spaces\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;66;03m# Discard `_last_obs`, this will force the env to reset before training\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;66;03m# See issue https://github.com/DLR-RM/stable-baselines3/issues/597\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_reset \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Joe\\Documents\\MachineLearningProjects\\StableBaselinesTutorials\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\utils.py:231\u001b[0m, in \u001b[0;36mcheck_for_correct_spaces\u001b[1;34m(env, observation_space, action_space)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03mChecks that the environment has same spaces as provided ones. Used by BaseAlgorithm to check if\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03mspaces match after loading the model with given env.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m:param action_space: Action space to check against\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_space \u001b[38;5;241m!=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space:\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObservation spaces do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action_space \u001b[38;5;241m!=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction spaces do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Observation spaces do not match: Box(0, 255, (4, 84, 84), uint8) != Box(0, 255, (3, 210, 160), uint8)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# going to leverage model on non-vectorized environment\n",
    "env = make_atari_env('Breakout-v4', n_envs=1, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "\n",
    "# load model\n",
    "a2c_path = os.path.join('Training','Saved Models','A2C_Breakout_Model')\n",
    "model = A2C.load(a2c_path, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joe\\Documents\\MachineLearningProjects\\StableBaselinesTutorials\\.venv\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.4, 2.0591260281974)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
